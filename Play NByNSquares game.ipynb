{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>\n",
    "A simple game to test the implementation of policy gradient.\n",
    "<br>\n",
    "In this game, a N by N game board is generated every turn. One cell will be labelled 1, all other cells are labelled 0.\n",
    "<br>\n",
    "The correct answer is simply the column number of the cell labelled as 1.\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from n_by_n_squares import NByNSquares\n",
    "from policy_gradient_nn import NeuralNetwork\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_n_games(nn, num_games, grid_size=2, max_rnd=10, gamma=0, fp_prob_random_select=0.1, choose_best_output=False, verbose=False):\n",
    "    advantage_all = []\n",
    "    for _ in range(num_games):\n",
    "        advantage = play_single_game(nn, grid_size, max_rnd, gamma, fp_prob_random_select, choose_best_output, verbose)\n",
    "        advantage_all.extend(advantage)\n",
    "    return np.array(advantage_all)\n",
    "\n",
    "def play_single_game(nn, grid_size=2, max_rnd=10, gamma=0, fp_prob_random_select=0.1, choose_best_output=False, verbose=False):\n",
    "    game = NByNSquares(grid_size, max_rnd, verbose=verbose)\n",
    "    reward = []\n",
    "    is_game_over = False\n",
    "    while not is_game_over:\n",
    "        is_game_over, reward_curr = play_single_round(nn, game, fp_prob_random_select, choose_best_output)\n",
    "        reward.append(reward_curr)\n",
    "        \n",
    "    advantage = calc_advantage(reward, gamma, max_rnd)\n",
    "    return advantage\n",
    "    \n",
    "def play_single_round(nn, game, fp_prob_random_select, choose_best_output=False):\n",
    "    game_grid_vector = game.get_vector_repr().reshape(-1, 1)\n",
    "    a_curr, action_curr = nn.fp(game_grid_vector, fp_prob_random_select, choose_best_output)\n",
    "    reward, is_game_over = game.take_action(action_curr[0])\n",
    "    return is_game_over, reward\n",
    "        \n",
    "def calc_advantage(reward, gamma, max_rnd):\n",
    "    advantage = [0 for i in range(max_rnd)]\n",
    "    prev_advantage = 0\n",
    "    for i in range(len(reward)-1, -1, -1):\n",
    "        curr_advantage = reward[i] + (gamma*prev_advantage)\n",
    "        advantage[i] = float(curr_advantage)\n",
    "        prev_advantage = float(curr_advantage)\n",
    "    return advantage\n",
    "\n",
    "def normalize_advantage(advantage):\n",
    "    normalized_advantage = np.array(advantage, dtype='float')\n",
    "    normalized_advantage -= np.mean(normalized_advantage)\n",
    "    normalized_advantage /= np.std(normalized_advantage)\n",
    "    return normalized_advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean advantage over 5 rounds at epoch 0: -1.3300919999999998\n",
      "Mean advantage over 5 rounds at epoch 20: -0.41495600000000005\n",
      "Mean advantage over 5 rounds at epoch 40: 0.46096400000000004\n",
      "Mean advantage over 5 rounds at epoch 60: 1.52834\n",
      "Mean advantage over 5 rounds at epoch 80: 2.3537\n",
      "Mean advantage over 5 rounds at epoch 100: 2.301212\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([9,28,28,3])\n",
    "\n",
    "for i in range(101):\n",
    "    advantage_all = play_n_games(nn, 5, grid_size=3, max_rnd=5, gamma=0.9, fp_prob_random_select=0.15)\n",
    "    mean_adv = np.mean(advantage_all)\n",
    "    normalized_advantage_all = normalize_advantage(advantage_all)\n",
    "    nn.bp(normalized_advantage_all)\n",
    "    nn.update_weights(0.2)\n",
    "    nn.clear_caches()\n",
    "    if i%20==0: \n",
    "        print('Mean advantage over 5 rounds at epoch {}: {}'.format(i, mean_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% rounds with correct answer: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# % rounds w/ correct answer, out of 1000 rounds\n",
    "rewards = play_n_games(nn, 100, grid_size=3, max_rnd=10, fp_prob_random_select=0, gamma=0, choose_best_output=True, verbose=False)\n",
    "nn.clear_caches()\n",
    "print('% rounds with correct answer: {}%'.format(np.mean(rewards)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:defaultenv]",
   "language": "python",
   "name": "conda-env-defaultenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
